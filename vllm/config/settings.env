# Model Configuration
MODEL_NAME=mistralai/Mixtral-8x7B-Instruct-v0.1
MODEL_PATH=/app/models/mistral-mixtral
MAX_MODEL_LEN=4096
QUANTIZATION=awq

# Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1
MAX_BATCH_SIZE=32
MAX_BATCH_TOKENS=4096

# GPU Configuration
GPU_MEMORY_UTILIZATION=0.9
TENSOR_PARALLEL_SIZE=1

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/vllm.log 